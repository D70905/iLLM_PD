% runOpenSourceExperiment_Fixed.m
% ä¿®æ­£ç‰ˆï¼šè§£å†³äº† URL é‡å¤å¯¼è‡´çš„ 404 é”™è¯¯ï¼Œå¹¶æ”¯æŒåˆ‡æ¢ Qwen
% ç›®æ ‡ï¼šå“åº” Nature Communications ç¼–è¾‘è¦æ±‚ï¼ŒéªŒè¯å¼€æºæ¨¡å‹

clear; clc; close all;

% æ·»åŠ æ ¸å¿ƒè·¯å¾„
addpath(genpath(pwd));

%% 1. åŸºç¡€å‚æ•°å®šä¹‰ (ä¿æŒä¸è®ºæ–‡ä¸€è‡´çš„ LTPP Case)
design_params = struct();
design_params.thickness = [15; 25; 20; 150]; % cm
design_params.modulus = [2500; 1200; 400; 50]; % MPa
design_params.poisson = [0.35; 0.40; 0.40; 0.45];
design_params.pavement_type = 'semi_rigid';
design_params.traffic_level = 'heavy';

% è·å–è®¾è®¡è§„èŒƒ
design_criteria = getJTG50DesignCriteria('Heavy traffic highway design', design_params);

% åˆå§‹ PDE è®¡ç®—
load_params = struct('load_pressure', 0.7, 'load_radius', 21.3);
bc = struct('method', 'multilayer_subgrade', 'soil_modulus', 50);
initial_pde = roadPDEModelingSimplified(design_params, load_params, bc);

%% 2. å®šä¹‰å®éªŒé…ç½®ï¼šé€‰æ‹©å¼€æºæ¨¡å‹

config_opensource = getDefaultOptimizedConfig();

% =======================================================
% ã€æ¨¡å‹é€‰æ‹©å¼€å…³ã€‘è¯·åœ¨è¿™é‡Œä¿®æ”¹ model åç§°
% =======================================================

% é€‰é¡¹ A: ä½¿ç”¨ Llama 3 (Meta) - éœ€å…ˆè¿è¡Œ 'ollama pull llama3'
% model_name = 'llama3'; 
% exp_name = 'OpenSource_Llama3';

% é€‰é¡¹ B: ä½¿ç”¨ Qwen 2.5 (Alibaba) - éœ€å…ˆè¿è¡Œ 'ollama pull qwen2.5:7b'
model_name = 'qwen2.5:7b'; 
exp_name = 'OpenSource_Qwen2.5';

config_opensource.experiment_name = exp_name;

% =======================================================
% ã€å…³é”®ä¿®å¤ã€‘Ollama API é…ç½®
% =======================================================
% 1. API Key: æ„é€ ä¸€ä¸ªå‡çš„ sk- å¼€å¤´ä¸”è¶³å¤Ÿé•¿çš„ Keyï¼Œç»•è¿‡ä»£ç æ ¡éªŒ
config_opensource.llm_api_config.api_key = 'sk-ollama-local-host-dummy-key-for-nc-test'; 

% 2. Base URL: ã€é‡è¦ã€‘å»æ‰æœ«å°¾çš„ /v1ï¼Œé¿å… RoadStructurePPO æ‹¼æ¥å‡ºåŒé‡ v1/v1
config_opensource.llm_api_config.base_url = 'http://localhost:11434'; 

% 3. æ¨¡å‹åç§°
config_opensource.llm_api_config.model = model_name;

% 4. å…¶ä»–å‚æ•°
config_opensource.llm_api_config.max_tokens = 500;
config_opensource.timeout_seconds = 60; % æœ¬åœ°æ¨ç†éœ€ç»™äºˆæ›´å¤šæ—¶é—´

%% 3. æ‰§è¡Œå®éªŒ

fprintf('================================================\n');
fprintf('   Starting Open-Source Model Verification\n');
fprintf('   Target Model: %s\n', model_name);
fprintf('================================================\n');

try
    % è°ƒç”¨æ ¸å¿ƒä¼˜åŒ–å‡½æ•°
    [opt_params_open, log_open] = runPPOOptimization(...
        design_params, config_opensource, design_criteria, initial_pde);
    
    % ä¿å­˜æ•°æ®
    save(['results_' exp_name '.mat'], 'opt_params_open', 'log_open');
    fprintf('âœ… Experiment completed successfully.\n');
    
    % æ£€æŸ¥æ˜¯å¦çœŸçš„è°ƒç”¨äº† LLM (æ£€æŸ¥æ—¥å¿—ä¸­çš„è°ƒç”¨æ¬¡æ•°)
    if isfield(log_open, 'price_llm_details')
        total_calls = sum(log_open.price_llm_details) + sum(log_open.engineering_llm_details);
        fprintf('ğŸ“Š Total LLM API Calls Made: %d\n', total_calls);
        if total_calls == 0
            fprintf('âš ï¸ Warning: No successful API calls recorded. Check Ollama status.\n');
        else
            fprintf('ğŸ‰ Success! Real interactions with %s confirmed.\n', model_name);
        end
    end
    
catch ME
    fprintf('âŒ Experiment failed. \nError: %s\n', ME.message);
end

%% 4. ç»“æœå¯è§†åŒ– (ç”Ÿæˆå›å¤ç¼–è¾‘çš„å›¾)

figure('Position', [100, 100, 800, 600], 'Color', 'w');
hold on; grid on;

% ç»˜åˆ¶å¥–åŠ±æ›²çº¿
if exist('log_open', 'var') && ~isempty(log_open.episode_rewards)
    plot(log_open.episode_rewards, 'o-', 'LineWidth', 2, 'Color', '#0072BD', ...
        'DisplayName', sprintf('iLLM-PD (Powered by %s)', model_name));
    
    xlabel('Training Episodes', 'FontSize', 12);
    ylabel('Total Reward', 'FontSize', 12);
    title(['Performance Consistency: ' model_name ' (Local Inference)'], 'FontSize', 14);
    legend('Location', 'southeast');
    
    % æ·»åŠ æ°´å°è¯æ˜æ˜¯æœ¬åœ°è¿è¡Œ
    text(1, min(log_open.episode_rewards), ...
        sprintf('Local Inference via Ollama\nAPI: localhost:11434'), ...
        'FontSize', 10, 'Color', [0.5 0.5 0.5]);
end

saveas(gcf, ['Response_to_Editor_' exp_name '_Validation.png']);
fprintf('\nğŸ“Š Validation plot generated: Response_to_Editor_%s_Validation.png\n', exp_name);

%% è¾…åŠ©å‡½æ•°ï¼šé…ç½®ç»“æ„ä½“
function config = getDefaultOptimizedConfig()
    config = struct();
    config.ablation_mode = 'full_system'; 
    config.max_training_episodes = 10;
    
    config.ppo = struct();
    config.ppo.max_episodes = 10;
    config.ppo.max_steps_per_episode = 6;
    config.ppo.learning_rate = 0.003;
    config.ppo.batch_size = 32;
    
    config.deepseek = struct(); 
    config.deepseek.guidance_enabled = true;
    
    config.llm_api_config = struct(); 
end